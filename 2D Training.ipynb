{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Random Seed: 416 ===========\n"
     ]
    }
   ],
   "source": [
    "from OurTrainingTools2D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W+Z, with new physics Parameters: ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "Only 1D Implemented in Training !\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphi4e-3.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.004, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphi4e-3.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_sm_1.h5\n",
      "##### File Info:\n",
      "SM = {0., 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_sm_1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Loaded SM Files:\n",
      "  XS[pb](avg.w)    #Data  ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "---------------  -------  ---------------------------------------\n",
      "       0.741835  3000000  tensor([[0., 0.]], dtype=torch.float64)\n",
      "\n",
      "Loaded BSM Files:\n",
      "  XS[pb](avg.w)    #Data  ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "---------------  -------  -----------------------------------------------\n",
      "       0.754596   500000  tensor([[0.0040, 0.0000]], dtype=torch.float64)\n",
      "\n",
      "Paired BSM/SM Datasets:\n",
      "\n",
      "  #Ev.SM    #Ev.BSM  ['Gphi[TeV**-2]', 'GW[TeV**-2]']                   Check\n",
      "--------  ---------  -----------------------------------------------  -------\n",
      " 3000000     500000  tensor([[0.0040, 0.0000]], dtype=torch.float64)   500000\n"
     ]
    }
   ],
   "source": [
    "DataFolder = '/data3/WZ_new_project/h5/Ideal_Data'\n",
    "\n",
    "temp = OurTrainingData([DataFolder + '/ChP_pt300_sm_1.h5',],\n",
    "                    [DataFolder + '/ChP_pt300_gphi4e-3.h5'],\n",
    "                     process = 'W+Z', parameters =['Gphi[TeV**-2]', 'GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurCDModel(nn.Module):\n",
    "### Defines the  model with parametrized discriminant. Only quadratic dependence on a single parameter is implemented.\n",
    "### Input is the architecture (list of integers, the last one being equal to 1) and the activation type ('ReLU' or 'Sigmoid')\n",
    "    def __init__(self, NumberOfParameters, AR = [1, 3, 3, 1] , AF = 'ReLU'):               \n",
    "        super(OurCDModel, self).__init__() \n",
    "        ValidActivationFunctions = {'ReLU': torch.relu, 'Sigmoid': torch.sigmoid}\n",
    "        try:\n",
    "            self.ActivationFunction = ValidActivationFunctions[AF]\n",
    "        except KeyError:\n",
    "            print('The activation function specified is not valid. Allowed activations are %s.'\n",
    "                 %str(list(ValidActivationFunctions.keys())))\n",
    "            print('Will use ReLU.')\n",
    "            self.ActivationFunction = torch.relu            \n",
    "        if type(AR) == list:\n",
    "            if( ( all(isinstance(n, int) for n in AR)) and ( AR[-1] == 1) ):\n",
    "                self.Architecture = AR\n",
    "            else:\n",
    "                print('Architecture should be a list of integers, the last one should be 1.')\n",
    "                raise ValueError             \n",
    "        else:\n",
    "            print('Architecture should be a list !')\n",
    "            raise ValueError\n",
    "        self.NumberOfParameters = NumberOfParameters\n",
    "\n",
    "### Define Layers\n",
    "        self.NumberOfNetworks = int((2+NumberOfParameters)*(1+NumberOfParameters)/2)-1\n",
    "        LinearLayers = [([nn.Linear(self.Architecture[i], self.Architecture[i+1]) \\\n",
    "                                  for i in range(len(self.Architecture)-1)])\\\n",
    "                        for n in range(self.NumberOfNetworks)]\n",
    "        LinearLayers = [Layer for SubLayerList in LinearLayers for Layer in SubLayerList]\n",
    "        self.LinearLayers = nn.ModuleList(LinearLayers)\n",
    "        \n",
    "    def Forward(self, Data, Parameters):\n",
    "### Forward Function. Performs Preprocessing, returns F = rho/(1+rho) in [0,1], where rho is quadratically parametrized.\n",
    "        # Checking that data has the right input dimension\n",
    "        InputDimension = self.Architecture[0]\n",
    "        if Data.size(1) != InputDimension:\n",
    "            print('Dimensions of the data and the network input mismatch: data: %d, model: %d'\n",
    "                  %(Data.size(1), InputDimension))\n",
    "            raise ValueError\n",
    "\n",
    "        # Checking that preprocess has been initialised\n",
    "        if not hasattr(self, 'Shift'):\n",
    "            print('Please initialize preprocess parameters!')\n",
    "            raise ValueError\n",
    "        with torch.no_grad(): \n",
    "            Data, Parameters = self.Preprocess(Data, Parameters)  \n",
    "        \n",
    "        NumberOfLayers, NumberOfEvents = len(self.Architecture)-1, Data.size(0)\n",
    "        EntryIterator, NetworkIterator = 0, -1\n",
    "        MatrixLT = torch.zeros([NumberOfEvents, (self.NumberOfParameters+1)**2], dtype=Data.dtype)\n",
    "        \n",
    "        if Data.is_cuda:\n",
    "            MatrixLT = OurCudaTensor(MatrixLT)\n",
    "        \n",
    "        for i in range(self.NumberOfParameters+1):\n",
    "            EntryIterator += i\n",
    "            DiagonalEntry = True\n",
    "            for j in range(self.NumberOfParameters+1-i):\n",
    "                if NetworkIterator == -1:\n",
    "                    MatrixLT[:, EntryIterator] = torch.ones(NumberOfEvents)\n",
    "                    #print('Entry: %d, Layer: ones, DiagonalEntry: %s'%(EntryIterator,\n",
    "                    #                                                str(DiagonalEntry)))\n",
    "                else:\n",
    "                    x = Data\n",
    "                    for Layer in self.LinearLayers[NumberOfLayers*NetworkIterator:\\\n",
    "                                                  NumberOfLayers*(NetworkIterator+1)-1]:\n",
    "                        x = self.ActivationFunction(Layer(x))\n",
    "                    x = self.LinearLayers[NumberOfLayers*(NetworkIterator+1)-1](x).squeeze()\n",
    "                    #MatrixLT[:, EntryIterator] = torch.exp(x) if DiagonalEntry else x\n",
    "                    MatrixLT[:, EntryIterator] = x\n",
    "                    #print('Entry: %d, Layer: %d, DiagonalEntry: %s'%(EntryIterator, NetworkIterator, \n",
    "                    #                                                str(DiagonalEntry)))\n",
    "                EntryIterator += 1\n",
    "                NetworkIterator += 1\n",
    "                DiagonalEntry = False\n",
    "        #print('MatrixLT: '+str(MatrixLT.is_cuda))\n",
    "        #print('Parameters: '+str(Parameters.is_cuda))\n",
    "\n",
    "        MatrixLT = MatrixLT.reshape([-1, self.NumberOfParameters+1, self.NumberOfParameters+1])\n",
    "        MatrixLTP = MatrixLT.matmul(Parameters.reshape([NumberOfEvents, self.NumberOfParameters+1, 1]))\n",
    "        rho = MatrixLTP.permute([0, 2, 1]).matmul(MatrixLTP).squeeze()\n",
    "        \n",
    "        return (rho.div(1.+rho)).view(-1, 1)\n",
    "    \n",
    "    def GetL1Bound(self, L1perUnit):\n",
    "        self.L1perUnit = L1perUnit\n",
    "    \n",
    "    def ClipL1Norm(self):\n",
    "### Clip the weights      \n",
    "        def ClipL1NormLayer(DesignatedL1Max, Layer, Counter):\n",
    "            if Counter == 1:\n",
    "                ### this avoids clipping the first layer\n",
    "                return\n",
    "            L1 = Layer.weight.abs().sum()\n",
    "            Layer.weight.masked_scatter_(L1 > DesignatedL1Max, \n",
    "                                        Layer.weight*(DesignatedL1Max/L1))\n",
    "            return\n",
    "        \n",
    "        Counter = 0\n",
    "        for m in self.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                Counter += 1\n",
    "                with torch.no_grad():\n",
    "                    DesignatedL1Max = m.weight.size(0)*m.weight.size(1)*self.L1perUnit\n",
    "                    ClipL1NormLayer(DesignatedL1Max, m, Counter)\n",
    "            else:\n",
    "                for mm in m:\n",
    "                    Counter +=1\n",
    "                    with torch.no_grad():\n",
    "                        DesignatedL1Max = mm.weight.size(0)*m.weight.size(1)*self.L1perUnit\n",
    "                        ClipL1NormLayer(DesignatedL1Max, mm, Counter)\n",
    "        return \n",
    "    \n",
    "    def DistributionRatio(self, points):\n",
    "### This is rho. I.e., after training, the estimator of the distribution ratio.\n",
    "        with torch.no_grad():\n",
    "            F = self(points)\n",
    "        return F/(1-F)\n",
    "\n",
    "    def InitPreprocess(self, Data, Parameters):\n",
    "### This can be run only ONCE to initialize the preprocess (shift and scaling) parameters\n",
    "### Takes as input the training Data and the training Parameters as Torch tensors.\n",
    "        if not hasattr(self, 'Scaling'):\n",
    "            print('Initializing Preprocesses Variables')\n",
    "            self.Scaling = Data.std(0)\n",
    "            self.Shift = Data.mean(0)\n",
    "            self.ParameterScaling = Parameters.std(0)  \n",
    "        else: print('Preprocess can be initialized only once. Parameters unchanged.')\n",
    "            \n",
    "    def Preprocess(self, Data, Parameters):\n",
    "### Returns scaled/shifted data and parameters\n",
    "### Takes as input Data and Parameters as Torch tensors.\n",
    "        if  not hasattr(self, 'Scaling'): print('Preprocess parameters are not initialized.')\n",
    "        Data = (Data - self.Shift)/self.Scaling\n",
    "        Parameters = Parameters/self.ParameterScaling\n",
    "        Ones = torch.ones([Parameters.size(0),1], dtype=Parameters.dtype)\n",
    "        if Parameters.is_cuda:\n",
    "            Ones = Ones.cuda()\n",
    "        Parameters = torch.cat([Ones, Parameters.reshape(Data.size(0), -1)], dim=1)\n",
    "        return Data, Parameters\n",
    "    \n",
    "    def Save(self, Name, Folder, csvFormat=False):\n",
    "### Saves the model in Folder/Name\n",
    "        FileName = Folder + Name + '.pth'\n",
    "        torch.save({'StateDict': self.state_dict(), \n",
    "                   'Scaling': self.Scaling,\n",
    "                   'Shift': self.Shift,\n",
    "                   'ParameterScaling': self.ParameterScaling}, \n",
    "                   FileName)\n",
    "        print('Model successfully saved.')\n",
    "        print('Path: %s'%str(FileName))\n",
    "        \n",
    "        if csvFormat:\n",
    "            modelparams = [w.detach().tolist() for w in self.parameters()]\n",
    "            np.savetxt(Folder + Name + ' (StateDict).csv', modelparams, '%s')\n",
    "            statistics = [self.Shift.detach().tolist(), self.Scaling.detach().tolist(),\n",
    "                         self.ParameterScaling.detach().tolist()]\n",
    "            np.savetxt(Folder + Name + ' (Statistics).csv', statistics, '%s')\n",
    "    \n",
    "    def Load(self, Name, Folder):\n",
    "### Loads the model from Folder/Name\n",
    "        FileName = Folder + Name + '.pth'\n",
    "        try:\n",
    "            IncompatibleKeys = self.load_state_dict(torch.load(FileName)['StateDict'])\n",
    "        except KeyError:\n",
    "            print('No state dictionary saved. Loading model failed.')\n",
    "            return \n",
    "        \n",
    "        if list(IncompatibleKeys)[0]:\n",
    "            print('Missing Keys: %s'%str(list(IncompatibleKeys)[0]))\n",
    "            print('Loading model failed. ')\n",
    "            return \n",
    "        \n",
    "        if list(IncompatibleKeys)[1]:\n",
    "            print('Unexpected Keys: %s'%str(list(IncompatibleKeys)[0]))\n",
    "            print('Loading model failed. ')\n",
    "            return \n",
    "        \n",
    "        self.Scaling = torch.load(FileName)['Scaling']\n",
    "        self.Shift = torch.load(FileName)['Shift']\n",
    "        self.ParameterScaling = torch.load(FileName)['ParameterScaling']\n",
    "        \n",
    "        print('Model successfully loaded.')\n",
    "        print('Path: %s'%str(FileName))\n",
    "        \n",
    "    def Report(self): ### is it possibe to check if the model is in double?\n",
    "        print('\\nModel Report:')\n",
    "        print('Preprocess Initialized: ' + str(hasattr(self, 'Shift')))\n",
    "        print('Architecture: ' + str(self.Architecture))\n",
    "        print('Loss Function: ' + 'Quadratic')\n",
    "        print('Activation: ' + str(self.ActivationFunction))\n",
    "        \n",
    "    def cuda(self):\n",
    "        nn.Module.cuda(self)\n",
    "        self.Shift = self.Shift.cuda()\n",
    "        self.Scaling = self.Scaling.cuda()\n",
    "        self.ParameterScaling = self.ParameterScaling.cuda()\n",
    "        \n",
    "    def cpu(self):\n",
    "        self.Shift = self.Shift.cpu()\n",
    "        self.Scaling = self.Scaling.cpu()\n",
    "        self.ParameterScaling = self.ParameterScaling.cpu()\n",
    "        return nn.Module.cpu(self)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurTrainingData():\n",
    "### Imports data for training. The Return() methods returns [self.Data, self.Labels, self.Weights, self.ParVal]\n",
    "### All values are in double precision\n",
    "### Inputs are the SM and BSM file paths and list of integers to chop the datasets if needed\n",
    "### Weights are normalized to have sum = 1 on the entire training sample\n",
    "    def __init__(self, SMfilepathlist, BSMfilepathlist, process, parameters, SMNLimits=\"NA\", BSMNLimits=\"NA\", verbose=True): \n",
    "        self.Process = process\n",
    "        self.Parameters = parameters\n",
    "        if verbose: print('Loading Data Files for Process: ' + str(self.Process) +', with new physics Parameters: ' + str(self.Parameters) ) \n",
    "        if len(self.Parameters)!= 1: print('Only 1D Implemented in Training !')   \n",
    "          \n",
    "####### Load BSM data (stored in self.BSMDataFiles)\n",
    "        if type(BSMfilepathlist) == list:\n",
    "            if all(isinstance(n, str) for n in BSMfilepathlist):\n",
    "                self.BSMDataFiles = [] \n",
    "                for path in BSMfilepathlist:\n",
    "                    temp =  DataFile(path, verbose=verbose)\n",
    "                    if((temp.Process == self.Process) and (set(list(temp.Parameters.flatten())) == set(self.Parameters)) and (sum(temp.Values.flatten()) != 0.) ):\n",
    "                        self.BSMDataFiles.append(temp)\n",
    "                    else: \n",
    "                        print('File not valid: ' + path)\n",
    "                        print('Parameters = ' + str(temp.Parameters) + ', Process = ' + str(temp.Process) \n",
    "                              +' and Values = ' + str(temp.Values.tolist()))\n",
    "                        print('should be = ' + str(self.Parameters) + ', = ' + str(self.Process) \n",
    "                              + ' and != ' + str(0.))\n",
    "                        raise ValueError\n",
    "                        self.BSMDataFiles.append(None) \n",
    "            else:\n",
    "                print('BSMfilepathlist input should be a list of strings !')\n",
    "                raise FileNotFoundError\n",
    "        else:\n",
    "            print('BSMfilepathlist input should be a list !')\n",
    "            raise FileNotFoundError\n",
    "                  \n",
    "###### Chop the BSM data sets (stored in BSMNDList, BSMDataList, BSMWeightsList, BSMParValList, BSMTargetList)\n",
    "        if type(BSMNLimits) == int:\n",
    "            BSMNLimits = [min(BSMNLimits, NF.ND) for NF in self.BSMDataFiles]\n",
    "        elif type(BSMNLimits) == list and all(isinstance(n, int) for n in BSMNLimits):\n",
    "            if len(BSMNLimits) != len(self.BSMDataFiles):\n",
    "                print(\"--> Please input %d integers to chop each SM file.\"%(\n",
    "                    len(self.BSMDataFiles)))\n",
    "                raise ValueError\n",
    "            elif sum([self.BSMDataFiles[i].ND >= BSMNLimits[i] for i in range(len(BSMNLimits))]\n",
    "                    ) != len(self.BSMDataFiles):\n",
    "                print(\"--> Some chop limit larger than available data in the corresponding file.\")\n",
    "                print(\"--> Lengths of the files: \"+str([file.ND for file in self.BSMDataFiles ]))\n",
    "                raise ValueError\n",
    "        else:\n",
    "            BSMNLimits =[file.ND for file in self.BSMDataFiles]   \n",
    "            \n",
    "        self.BSMNDList = BSMNLimits\n",
    "        #self.BSMNData = sum(self.BSMNDataList)\n",
    "        self.BSMDataList = [DF.Data[:N] for (DF, N) in zip(\n",
    "            self.BSMDataFiles, self.BSMNDList)]\n",
    "        self.BSMWeightsList = [DF.Weights[:N] for (DF, N) in zip(\n",
    "            self.BSMDataFiles, self.BSMNDList)] \n",
    "        self.BSMXSList = [DF.XS for DF in self.BSMDataFiles]\n",
    "        self.BSMParValList =  [torch.ones([N, len(self.Parameters)], dtype=torch.double)*DF.Values for (DF, N) in zip(self.BSMDataFiles, self.BSMNDList)]\n",
    "        self.BSMTargetList = [torch.ones(N, dtype=torch.double) for N in self.BSMNDList] \n",
    "        \n",
    "        \n",
    "####### Load SM data (stored in SMDataFiles)\n",
    "        if type(SMfilepathlist) == list:\n",
    "            if all(isinstance(n, str) for n in SMfilepathlist):\n",
    "                #self.SMFilePathList = SMfilepathlist\n",
    "                #self.SMNumFiles = len(self.SMFilePathList)\n",
    "                self.SMDataFiles = []\n",
    "                for path in SMfilepathlist:\n",
    "                    temp =  DataFile(path, verbose=verbose)\n",
    "                    if( (temp.Process == self.Process) and (temp.Parameters[0] == 'SM') and (sum(temp.Values.flatten()) == 0.) ):\n",
    "                        self.SMDataFiles.append(temp)\n",
    "                    else:\n",
    "                        print('File not valid: ' + path)\n",
    "                        print('Parameters = ' + str(temp.Parameters) + ', Process = ' + str(temp.Process) \n",
    "                              +' and Values = ' + str(temp.Values.tolist()))\n",
    "                        print('should be = ' + 'SM'+ ', = ' + str(self.Process) \n",
    "                              + ' and = ' + str(0.))\n",
    "                        self.SMDataFiles.append(None)                    \n",
    "            else:\n",
    "                print('SMfilepathlist input should be a list of strings !')\n",
    "                raise FileNotFoundError\n",
    "        else:\n",
    "            print('SMfilepathlist input should be a list !')\n",
    "            raise FileNotFoundError\n",
    "            \n",
    "####### Chop the SM data sets and join them in one (stored in SMND, SMData and SMWeights)\n",
    "        if type(SMNLimits) == int:\n",
    "            SMNLimits = [min(SMNLimits, DF.ND) for DF in self.SMDataFiles]\n",
    "        elif type(SMNLimits) == list and all(isinstance(n, int) for n in SMNLimits):\n",
    "            if len(SMNLimits) != len(self.SMDataFiles):\n",
    "                print(\"--> Please input %d integers to chop each SM file.\"%(\n",
    "                    len(self.SMDataFiles)))\n",
    "                raise ValueError\n",
    "            elif sum([self.SMDataFiles[i].ND >= SMNLimits[i] for i in range(len(SMNLimits))]\n",
    "                    ) != len(self.SMDataFiles):\n",
    "                print(\"--> Some chop limit larger than available data in the corresponding file.\")\n",
    "                print(\"--> Lengths of the files: \" + str([file.ND for file in self.SMDataFiles]))\n",
    "                raise ValueError\n",
    "        else:\n",
    "            SMNLimits = [file.ND for file in self.SMDataFiles]\n",
    "        self.SMND = sum(SMNLimits)\n",
    "        self.SMData = torch.cat(\n",
    "            [DF.Data[:N] for (DF, N) in zip(self.SMDataFiles, SMNLimits)]\n",
    "            , 0) \n",
    "        self.SMWeights = torch.cat(\n",
    "            [DF.Weights[:N] for (DF, N) in zip(self.SMDataFiles, SMNLimits)]\n",
    "            , 0)\n",
    "        self.SMXSList = [DF.XS for DF in self.SMDataFiles]\n",
    "        \n",
    "        \n",
    "        #idx_random = torch.randperm(self.SMND)\n",
    "        #self.SMData = self.SMData[idx_random, :]\n",
    "        #self.SMWeights = self.SMWeights[idx_random]\n",
    "\n",
    "####### Break SM data in blocks to be paired with BSM data (stored in UsedSMNDList, UsedSMDataList, UsedSMWeightsList, UsedSMParValList, UsedSMTargetList)\n",
    "        BSMNRatioDataList = [torch.tensor(1., dtype=torch.double)*n/sum(self.BSMNDList\n",
    "                                                                       ) for n in self.BSMNDList]\n",
    "        self.UsedSMNDList = [int(self.SMND*BSMNRatioData) for BSMNRatioData in BSMNRatioDataList] \n",
    "        #self.UsedSMNData = sum(self.UsedSMNDataList)\n",
    "        #self.UsedSMData = self.SMData[: self.UsedSMND]\n",
    "        self.UsedSMDataList =  self.SMData[:sum(self.UsedSMNDList)].split(self.UsedSMNDList)\n",
    "        \n",
    "    ##### Reweighting is performed such that the SUM of the SM weights in each block equals the number of BSM data times the AVERAGE \n",
    "    ##### of the original weights. This equals the SM cross-section as obtained in the specific sample at hand, times NBSM\n",
    "        self.UsedSMWeightsList = self.SMWeights[:sum(self.UsedSMNDList)].split(self.UsedSMNDList)\n",
    "        self.UsedSMWeightsList = [ self.UsedSMWeightsList[i]*self.BSMNDList[i]/self.UsedSMNDList[i] for i in range(len(BSMNRatioDataList))]   \n",
    "        self.UsedSMParValList =  [torch.ones([N, len(self.Parameters)], dtype=torch.double)*DF.Values for (DF, N) in zip(self.BSMDataFiles, self.UsedSMNDList)]       \n",
    "        self.UsedSMTargetList = [torch.zeros(N, dtype=torch.double) for N in self.UsedSMNDList]\n",
    "\n",
    "####### Join SM with BSM data\n",
    "        self.Data = torch.cat(\n",
    "            [torch.cat([self.UsedSMDataList[i], self.BSMDataList[i]]\n",
    "                                  ) for i in range(len(self.BSMDataList))]\n",
    "            )\n",
    "        self.Weights = torch.cat(\n",
    "            [torch.cat([self.UsedSMWeightsList[i], self.BSMWeightsList[i]]\n",
    "                                  ) for i in range(len(self.BSMWeightsList))]\n",
    "            )\n",
    "        self.Labels = torch.cat(\n",
    "            [torch.cat([self.UsedSMTargetList[i], self.BSMTargetList[i]]\n",
    "                                  ) for i in range(len(self.BSMTargetList))]\n",
    "            )\n",
    "        self.ParVal = torch.cat(\n",
    "            [torch.cat([self.UsedSMParValList[i], self.BSMParValList[i]]\n",
    "                                  ) for i in range(len(self.BSMParValList))]\n",
    "            )\n",
    "        \n",
    "####### Final reweighting\n",
    "        s = self.Weights.sum()\n",
    "        self.Weights = self.Weights.div(s)\n",
    "\n",
    "####### If verbose, display report\n",
    "        if verbose: self.Report()\n",
    "        \n",
    "####### Return Tranining Data\n",
    "    def ReturnData(self):\n",
    "        return [self.Data, self.Labels, self.Weights, self.ParVal]\n",
    "            \n",
    "    def Report(self):\n",
    "        #from tabulate import tabulate\n",
    "        print('\\nLoaded SM Files:')\n",
    "        print(tabulate({str(self.Parameters): [ file.Values for file in self.SMDataFiles ], \n",
    "                        \"#Data\":[ file.ND for file in self.SMDataFiles ], \n",
    "                        \"XS[pb](avg.w)\":[ file.XS for file in self.SMDataFiles ]}, headers=\"keys\"))\n",
    "        print('\\nLoaded BSM Files:')\n",
    "        print(tabulate({str(self.Parameters): [ file.Values for file in self.BSMDataFiles ], \n",
    "                        \"#Data\":[ file.ND for file in self.BSMDataFiles ], \n",
    "                        \"XS[pb](avg.w)\":[ file.XS for file in self.BSMDataFiles ]}, headers=\"keys\"))\n",
    "        print('\\nPaired BSM/SM Datasets:\\n')\n",
    "        ### Check should be nearly equal to #EV.BSM. It is computed with the weights BEFORE final reweighting\n",
    "        print(tabulate({str(self.Parameters): [ file.Values for file in self.BSMDataFiles ], \"#Ev.BSM\": self.BSMNDList\n",
    "                        , \"#Ev.SM\": self.UsedSMNDList,\n",
    "                        \"Check\": [(self.UsedSMWeightsList[i].sum())/(self.SMWeights.mean()) for i in range(len(self.BSMDataFiles))]\n",
    "                       }, headers=\"keys\"))    \n",
    "        \n",
    "####### Convert Angles\n",
    "    def CurateAngles(self, AnglePos):\n",
    "        Angles = self.Data[:, AnglePos]\n",
    "        CuratedAngles = torch.cat([torch.sin(Angles), torch.cos(Angles)], dim=1)\n",
    "        OtherPos = list(set(range(self.Data.size(1)))-set(AnglePos))\n",
    "        self.Data = torch.cat([self.Data[:, OtherPos], CuratedAngles], dim=1)\n",
    "        print('####\\nAnlges at position %s have been converted to Sin and Cos and put at the last columns of the Data.'%(AnglePos))\n",
    "        print('####')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W+Z, with new physics Parameters: ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "Only 1D Implemented in Training !\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphi2e-1_gw1e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.2, 0.1}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphi2e-1_gw1e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphi5e-1_gw2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.5, 0.2}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphi5e-1_gw2e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphim2e-1_gw1e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.2, 0.1}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphim2e-1_gw1e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphim5e-1_gw2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.5, 0.2}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphim5e-1_gw2e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphim5e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.5, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphim5e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphim2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.2, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphim2e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphim5e-2.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.05, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphim5e-2.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphi5e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.5, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphi5e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphi2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.2, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphi2e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gphi5e-2.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.05, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gphi5e-2.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gwm5e-2.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., -0.05}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gwm5e-2.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gwm1e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., -0.1}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gwm1e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gwm2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., -0.2}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gwm2e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gw5e-2.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., 0.05}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gw5e-2.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gw1e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., 0.1}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gw1e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_gw2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., 0.2}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_gw2e-1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChP_pt300_sm_1.h5\n",
      "##### File Info:\n",
      "SM = {0., 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChP_pt300_sm_1.dat.gz\n",
      "Charge = 1 --- Process = W+Z\n",
      "#####\n",
      "\n",
      "Loaded SM Files:\n",
      "  XS[pb](avg.w)    #Data  ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "---------------  -------  ---------------------------------------\n",
      "       0.741835  3000000  tensor([[0., 0.]], dtype=torch.float64)\n",
      "\n",
      "Loaded BSM Files:\n",
      "  XS[pb](avg.w)    #Data  ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "---------------  -------  -------------------------------------------------\n",
      "       2.45948    500000  tensor([[0.2000, 0.1000]], dtype=torch.float64)\n",
      "       8.4987     500000  tensor([[0.5000, 0.2000]], dtype=torch.float64)\n",
      "       1.22171    500000  tensor([[-0.2000,  0.1000]], dtype=torch.float64)\n",
      "       5.40484    500000  tensor([[-0.5000,  0.2000]], dtype=torch.float64)\n",
      "       4.23431    500000  tensor([[-0.5000,  0.0000]], dtype=torch.float64)\n",
      "       0.929192   500000  tensor([[-0.2000,  0.0000]], dtype=torch.float64)\n",
      "       0.637632   500000  tensor([[-0.0500,  0.0000]], dtype=torch.float64)\n",
      "       7.32829    500000  tensor([[0.5000, 0.0000]], dtype=torch.float64)\n",
      "       2.16749    500000  tensor([[0.2000, 0.0000]], dtype=torch.float64)\n",
      "       0.947113   500000  tensor([[0.0500, 0.0000]], dtype=torch.float64)\n",
      "       0.814992   500000  tensor([[ 0.0000, -0.0500]], dtype=torch.float64)\n",
      "       1.03408    500000  tensor([[ 0.0000, -0.1000]], dtype=torch.float64)\n",
      "       1.91084    500000  tensor([[ 0.0000, -0.2000]], dtype=torch.float64)\n",
      "       0.815234   500000  tensor([[0.0000, 0.0500]], dtype=torch.float64)\n",
      "       1.03439    500000  tensor([[0.0000, 0.1000]], dtype=torch.float64)\n",
      "       1.91103    500000  tensor([[0.0000, 0.2000]], dtype=torch.float64)\n",
      "\n",
      "Paired BSM/SM Datasets:\n",
      "\n",
      "  #Ev.SM    #Ev.BSM  ['Gphi[TeV**-2]', 'GW[TeV**-2]']                     Check\n",
      "--------  ---------  -------------------------------------------------  -------\n",
      "  187500     500000  tensor([[0.2000, 0.1000]], dtype=torch.float64)     500000\n",
      "  187500     500000  tensor([[0.5000, 0.2000]], dtype=torch.float64)     500000\n",
      "  187500     500000  tensor([[-0.2000,  0.1000]], dtype=torch.float64)   500000\n",
      "  187500     500000  tensor([[-0.5000,  0.2000]], dtype=torch.float64)   500000\n",
      "  187500     500000  tensor([[-0.5000,  0.0000]], dtype=torch.float64)   500000\n",
      "  187500     500000  tensor([[-0.2000,  0.0000]], dtype=torch.float64)   500000\n",
      "  187500     500000  tensor([[-0.0500,  0.0000]], dtype=torch.float64)   500000\n",
      "  187500     500000  tensor([[0.5000, 0.0000]], dtype=torch.float64)     500000\n",
      "  187500     500000  tensor([[0.2000, 0.0000]], dtype=torch.float64)     500000\n",
      "  187500     500000  tensor([[0.0500, 0.0000]], dtype=torch.float64)     500000\n",
      "  187500     500000  tensor([[ 0.0000, -0.0500]], dtype=torch.float64)   500000\n",
      "  187500     500000  tensor([[ 0.0000, -0.1000]], dtype=torch.float64)   500000\n",
      "  187500     500000  tensor([[ 0.0000, -0.2000]], dtype=torch.float64)   500000\n",
      "  187500     500000  tensor([[0.0000, 0.0500]], dtype=torch.float64)     500000\n",
      "  187500     500000  tensor([[0.0000, 0.1000]], dtype=torch.float64)     500000\n",
      "  187500     500000  tensor([[0.0000, 0.2000]], dtype=torch.float64)     500000\n"
     ]
    }
   ],
   "source": [
    "DataFolder = '/data3/WZ_new_project/h5/Ideal_Data'\n",
    "\n",
    "td = OurTrainingData([DataFolder + '/ChP_pt300_sm_1.h5',],\n",
    "                    [DataFolder + '/ChP_pt300_gphi2e-1_gw1e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphi5e-1_gw2e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphim2e-1_gw1e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphim5e-1_gw2e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphim5e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphim2e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphim5e-2.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphi5e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphi2e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gphi5e-2.h5',\n",
    "                     DataFolder + '/ChP_pt300_gwm5e-2.h5',\n",
    "                     DataFolder + '/ChP_pt300_gwm1e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gwm2e-1.h5',                     \n",
    "                     DataFolder + '/ChP_pt300_gw5e-2.h5',\n",
    "                     DataFolder + '/ChP_pt300_gw1e-1.h5',\n",
    "                     DataFolder + '/ChP_pt300_gw2e-1.h5'],\n",
    "                     process = 'W+Z', parameters =['Gphi[TeV**-2]', 'GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####\n",
      "Anlges at position [3, 5] have been converted to Sin and Cos and put at the last columns of the Data.\n",
      "####\n",
      "Initializing Preprocesses Variables\n",
      "Model successfully loaded.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 10000 epoch.pth\n"
     ]
    }
   ],
   "source": [
    "NumEpochs = int(1e4)\n",
    "\n",
    "td.Data = td.Data[:, :7]\n",
    "td.CurateAngles([3, 5])\n",
    "\n",
    "Data, ParVal, Labels, Weights = td.Data, td.ParVal, td.Labels, td.Weights\n",
    "Data, ParVal, Labels, Weights = Data.float(), ParVal.float(), Labels.float(), Weights.float()\n",
    "\n",
    "model_name = 'ChPgphigw, (16 BSM, 500k, CD), 10000 epoch'\n",
    "\n",
    "MD = OurCDModel(NumberOfParameters=2, AR=[9,32,32,32,1])\n",
    "MD.InitPreprocess(Data, ParVal)\n",
    "MD.Load(model_name, os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####\n",
      "Anlges at position [3, 5] have been converted to Sin and Cos and put at the last columns of the Data.\n",
      "####\n",
      "Initializing Preprocesses Variables\n",
      "Training epoch 10 (took 46.86 sec, time left 11:49:16.879175 sec) loss 0.20788951\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 10 epoch.pth\n",
      "Training epoch 100 (took 438.66 sec, time left 13:13:06.146870 sec) loss 0.14213464\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 100 epoch.pth\n",
      "Training epoch 500 (took 1914.07 sec, time left 12:38:16.506502 sec) loss 0.13176727\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 500 epoch.pth\n",
      "Training epoch 1000 (took 2391.70 sec, time left 11:57:53.837132 sec) loss 0.13091810\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 1000 epoch.pth\n",
      "Training epoch 2000 (took 4750.68 sec, time left 10:35:44.101537 sec) loss 0.13049816\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 2000 epoch.pth\n",
      "Training epoch 3000 (took 4740.51 sec, time left 9:15:09.977108 sec) loss 0.13037047\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 3000 epoch.pth\n",
      "Training epoch 4000 (took 4744.52 sec, time left 7:55:28.641679 sec) loss 0.13029221\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 4000 epoch.pth\n",
      "Training epoch 5000 (took 4748.61 sec, time left 6:36:06.124798 sec) loss 0.13022913\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 5000 epoch.pth\n",
      "Training epoch 6000 (took 4747.67 sec, time left 5:16:47.612499 sec) loss 0.13018429\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 6000 epoch.pth\n",
      "Training epoch 7000 (took 4720.60 sec, time left 3:57:20.604038 sec) loss 0.13015078\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 7000 epoch.pth\n",
      "Training epoch 8000 (took 4688.14 sec, time left 2:37:57.086673 sec) loss 0.13012248\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 8000 epoch.pth\n",
      "Training epoch 9000 (took 4691.45 sec, time left 1:18:50.683514 sec) loss 0.13009921\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 9000 epoch.pth\n",
      "Training epoch 10000 (took 4706.32 sec, time left -1 day, 23:59:55.267491 sec) loss 0.13008310\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), 10000 epoch.pth\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChPgphigw, (16 BSM, 500k, CD), Final.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OurCDModel(\n",
       "  (LinearLayers): ModuleList(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (5): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (7): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (8): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (9): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (10): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (11): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (12): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (13): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (14): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (15): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (16): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (17): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (18): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (19): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumEpochs = int(1e4)\n",
    "\n",
    "td.Data = td.Data[:, :7]\n",
    "td.CurateAngles([3, 5])\n",
    "\n",
    "Data, ParVal, Labels, Weights = td.Data, td.ParVal, td.Labels, td.Weights\n",
    "Data, ParVal, Labels, Weights = Data.float(), ParVal.float(), Labels.float(), Weights.float()\n",
    "\n",
    "MD = OurCDModel(NumberOfParameters=2, AR=[9,32,32,32,1])\n",
    "MD.InitPreprocess(Data, ParVal)\n",
    "\n",
    "OT = OurTrainer(NumEpochs = NumEpochs)\n",
    "OT.SetSaveAfterEpochs([10,100,500]+list(range(1000, 11000, 1000)))\n",
    "\n",
    "OT.Train(MD, Data = Data, Parameters = ParVal, Labels=Labels, Weights= Weights, bs = 100000,\n",
    "        Name = 'ChPgphigw, (16 BSM, 500k, CD), ', Folder = os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Files for Process: W-Z, with new physics Parameters: ['Gphi[TeV**-2]', 'GW[TeV**-2]']\n",
      "Only 1D Implemented in Training !\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphi2e-1_gw1e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.2, 0.1}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphi2e-1_gw1e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphi5e-1_gw2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.5, 0.2}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphi5e-1_gw2e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphim2e-1_gw1e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.2, 0.1}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphim2e-1_gw1e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphim5e-1_gw2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.5, 0.2}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphim5e-1_gw2e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphim5e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.5, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphim5e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphim2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.2, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphim2e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphim5e-2.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {-0.05, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphim5e-2.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphi5e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.5, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphi5e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphi2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.2, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphi2e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gphi5e-2.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0.05, 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gphi5e-2.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gwm5e-2.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., -0.05}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gwm5e-2.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gwm1e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., -0.1}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gwm1e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gwm2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., -0.2}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gwm2e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gw5e-2.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., 0.05}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gw5e-2.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gw1e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., 0.1}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gw1e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_gw2e-1.h5\n",
      "##### File Info:\n",
      "{Gphi[TeV**-2], GW[TeV**-2]} = {0., 0.2}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_gw2e-1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Reading file .../data3/WZ_new_project/h5/Ideal_Data/ChM_pt300_sm_1.h5\n",
      "##### File Info:\n",
      "SM = {0., 0.}[TeV**-2] data, Ideal Events. \n",
      "Event format: {{s, θ, θZ, ϕZ, θWrec, ϕWrec, PtZ}, weight}.\n",
      "Converted from /data3/WZ_new_project/dat/Ideal_Events/ChM_pt300_sm_1.dat.gz\n",
      "Charge = -1 --- Process = W-Z\n",
      "#####\n",
      "\n",
      "Loaded SM Files:\n",
      "['Gphi[TeV**-2]', 'GW[TeV**-2]']           #Data    XS[pb](avg.w)\n",
      "---------------------------------------  -------  ---------------\n",
      "tensor([[0., 0.]], dtype=torch.float64)  3000000         0.329009\n",
      "\n",
      "Loaded BSM Files:\n",
      "['Gphi[TeV**-2]', 'GW[TeV**-2]']                     #Data    XS[pb](avg.w)\n",
      "-------------------------------------------------  -------  ---------------\n",
      "tensor([[0.2000, 0.1000]], dtype=torch.float64)     500000         1.04509\n",
      "tensor([[0.5000, 0.2000]], dtype=torch.float64)     500000         3.50834\n",
      "tensor([[-0.2000,  0.1000]], dtype=torch.float64)   500000         0.494724\n",
      "tensor([[-0.5000,  0.2000]], dtype=torch.float64)   500000         2.13244\n",
      "tensor([[-0.5000,  0.0000]], dtype=torch.float64)   500000         1.66333\n",
      "tensor([[-0.2000,  0.0000]], dtype=torch.float64)   500000         0.377384\n",
      "tensor([[-0.0500,  0.0000]], dtype=torch.float64)   500000         0.280429\n",
      "tensor([[0.5000, 0.0000]], dtype=torch.float64)     500000         3.03977\n",
      "tensor([[0.2000, 0.0000]], dtype=torch.float64)     500000         0.927797\n",
      "tensor([[0.0500, 0.0000]], dtype=torch.float64)     500000         0.418017\n",
      "tensor([[ 0.0000, -0.0500]], dtype=torch.float64)   500000         0.358355\n",
      "tensor([[ 0.0000, -0.1000]], dtype=torch.float64)   500000         0.446333\n",
      "tensor([[ 0.0000, -0.2000]], dtype=torch.float64)   500000         0.798199\n",
      "tensor([[0.0000, 0.0500]], dtype=torch.float64)     500000         0.358314\n",
      "tensor([[0.0000, 0.1000]], dtype=torch.float64)     500000         0.446264\n",
      "tensor([[0.0000, 0.2000]], dtype=torch.float64)     500000         0.798166\n",
      "\n",
      "Paired BSM/SM Datasets:\n",
      "\n",
      "['Gphi[TeV**-2]', 'GW[TeV**-2]']                     #Ev.BSM    #Ev.SM    Check\n",
      "-------------------------------------------------  ---------  --------  -------\n",
      "tensor([[0.2000, 0.1000]], dtype=torch.float64)       500000    187500   500000\n",
      "tensor([[0.5000, 0.2000]], dtype=torch.float64)       500000    187500   500000\n",
      "tensor([[-0.2000,  0.1000]], dtype=torch.float64)     500000    187500   500000\n",
      "tensor([[-0.5000,  0.2000]], dtype=torch.float64)     500000    187500   500000\n",
      "tensor([[-0.5000,  0.0000]], dtype=torch.float64)     500000    187500   500000\n",
      "tensor([[-0.2000,  0.0000]], dtype=torch.float64)     500000    187500   500000\n",
      "tensor([[-0.0500,  0.0000]], dtype=torch.float64)     500000    187500   500000\n",
      "tensor([[0.5000, 0.0000]], dtype=torch.float64)       500000    187500   500000\n",
      "tensor([[0.2000, 0.0000]], dtype=torch.float64)       500000    187500   500000\n",
      "tensor([[0.0500, 0.0000]], dtype=torch.float64)       500000    187500   500000\n",
      "tensor([[ 0.0000, -0.0500]], dtype=torch.float64)     500000    187500   500000\n",
      "tensor([[ 0.0000, -0.1000]], dtype=torch.float64)     500000    187500   500000\n",
      "tensor([[ 0.0000, -0.2000]], dtype=torch.float64)     500000    187500   500000\n",
      "tensor([[0.0000, 0.0500]], dtype=torch.float64)       500000    187500   500000\n",
      "tensor([[0.0000, 0.1000]], dtype=torch.float64)       500000    187500   500000\n",
      "tensor([[0.0000, 0.2000]], dtype=torch.float64)       500000    187500   500000\n"
     ]
    }
   ],
   "source": [
    "DataFolder = '/data3/WZ_new_project/h5/Ideal_Data'\n",
    "\n",
    "td = OurTrainingData([DataFolder + '/ChM_pt300_sm_1.h5',],\n",
    "                    [DataFolder + '/ChM_pt300_gphi2e-1_gw1e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphi5e-1_gw2e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphim2e-1_gw1e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphim5e-1_gw2e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphim5e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphim2e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphim5e-2.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphi5e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphi2e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gphi5e-2.h5',\n",
    "                     DataFolder + '/ChM_pt300_gwm5e-2.h5',\n",
    "                     DataFolder + '/ChM_pt300_gwm1e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gwm2e-1.h5',                     \n",
    "                     DataFolder + '/ChM_pt300_gw5e-2.h5',\n",
    "                     DataFolder + '/ChM_pt300_gw1e-1.h5',\n",
    "                     DataFolder + '/ChM_pt300_gw2e-1.h5'],\n",
    "                     process = 'W-Z', parameters =['Gphi[TeV**-2]', 'GW[TeV**-2]'], \n",
    "                     SMNLimits=int(3e6),\n",
    "                     BSMNLimits=int(5e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####\n",
      "Anlges at position [3, 5] have been converted to Sin and Cos and put at the last columns of the Data.\n",
      "####\n",
      "Initializing Preprocesses Variables\n",
      "Training epoch 10 (took 47.61 sec, time left 12:00:37.310181 sec) loss 0.20726699\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 10 epoch.pth\n",
      "Training epoch 100 (took 424.16 sec, time left 12:50:38.328980 sec) loss 0.14772467\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 100 epoch.pth\n",
      "Training epoch 500 (took 1882.06 sec, time left 12:23:48.882847 sec) loss 0.13859846\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 500 epoch.pth\n",
      "Training epoch 1000 (took 2345.38 sec, time left 11:44:06.015365 sec) loss 0.13774814\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 1000 epoch.pth\n",
      "Training epoch 2000 (took 4685.88 sec, time left 10:25:16.972865 sec) loss 0.13739106\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 2000 epoch.pth\n",
      "Training epoch 3000 (took 4686.55 sec, time left 9:06:58.244831 sec) loss 0.13725689\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 3000 epoch.pth\n",
      "Training epoch 4000 (took 4696.72 sec, time left 7:49:00.847319 sec) loss 0.13718700\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 4000 epoch.pth\n",
      "Training epoch 5000 (took 4692.38 sec, time left 6:30:51.387791 sec) loss 0.13713506\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 5000 epoch.pth\n",
      "Training epoch 6000 (took 4690.76 sec, time left 5:12:39.869867 sec) loss 0.13709646\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 6000 epoch.pth\n",
      "Training epoch 7000 (took 4678.10 sec, time left 3:54:23.144193 sec) loss 0.13706841\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 7000 epoch.pth\n",
      "Training epoch 8000 (took 4702.72 sec, time left 2:36:17.225581 sec) loss 0.13704148\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 8000 epoch.pth\n",
      "Training epoch 9000 (took 4699.82 sec, time left 1:18:07.251339 sec) loss 0.13701625\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 9000 epoch.pth\n",
      "Training epoch 10000 (took 4691.52 sec, time left -1 day, 23:59:55.308099 sec) loss 0.13699690\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), 10000 epoch.pth\n",
      "Model successfully saved.\n",
      "Path: /home/chen/Documents/2DQuadraticClassifier/TrainedModels/ChMgphigw, (16 BSM, 500k, CD), Final.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OurCDModel(\n",
       "  (LinearLayers): ModuleList(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (5): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (7): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (8): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (9): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (10): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (11): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (12): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (13): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (14): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (15): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (16): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (17): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (18): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (19): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumEpochs = int(1e4)\n",
    "\n",
    "td.Data = td.Data[:, :7]\n",
    "td.CurateAngles([3, 5])\n",
    "\n",
    "Data, ParVal, Labels, Weights = td.Data, td.ParVal, td.Labels, td.Weights\n",
    "Data, ParVal, Labels, Weights = Data.float(), ParVal.float(), Labels.float(), Weights.float()\n",
    "\n",
    "MD = OurCDModel(NumberOfParameters=2, AR=[9,32,32,32,1])\n",
    "MD.InitPreprocess(Data, ParVal)\n",
    "\n",
    "OT = OurTrainer(NumEpochs = NumEpochs)\n",
    "OT.SetSaveAfterEpochs([10,100,500]+list(range(1000, 11000, 1000)))\n",
    "\n",
    "OT.Train(MD, Data = Data, Parameters = ParVal, Labels=Labels, Weights= Weights, bs = 100000,\n",
    "        Name = 'ChMgphigw, (16 BSM, 500k, CD), ', Folder = os.getcwd()+'/TrainedModels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
